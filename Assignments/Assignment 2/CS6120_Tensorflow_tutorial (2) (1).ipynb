{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXoi1PrTpeHY"
   },
   "source": [
    "# CS6120 Natural Language Processing by Professor Uzair Ahmad. \n",
    "\n",
    "## Tensorflow Tutorial. \n",
    "\n",
    "## In this tutorial we are gonna learn about building deep neural networks with tensorflow/keras. For this tutorial we are going to build a classifier model to classify the given surname. \n",
    "\n",
    "## This work is inspired from https://github.com/DrUzair/NLP/tree/master/textclassification/surnames/mlp. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLVBxSaDCxeP"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AJK_Dzq8q2BU"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import unicodedata\n",
    "import string\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yu--Nj7Wq2lq"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9s4lnVFobM9",
    "outputId": "c012fb8d-c554-405a-acad-6fb065bff11f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category = Vietnamese / line = Phi\n",
      "category = Spanish / line = Reyes\n",
      "category = Arabic / line = Zogby\n",
      "category = Dutch / line = Vliert\n",
      "category = Greek / line = Dasios\n",
      "category = German / line = Breisacher\n",
      "category = Chinese / line = Rao\n",
      "category = Italian / line = Piovene\n",
      "category = French / line = Langlois\n",
      "category = Greek / line = Kouropoulos\n"
     ]
    }
   ],
   "source": [
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = np.zeros((len(line), 1, n_letters))\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# Build the category_lines dictionary, a list of lines per category\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "for filename in findFiles('/content/drive/MyDrive/names_data/names/*.txt'):\n",
    "    category = filename.split(\"/\")[-1].split('.')[0].replace('names\\\\','')\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "import random\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)] \n",
    "\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    category_tensor = np.array([all_categories.index(category)])\n",
    "    line_tensor = lineToTensor(line.lower())\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "def test():\n",
    "    for i in range(10):\n",
    "        category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "        print('category =', category, '/ line =', line)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRHfgxFhLF7t"
   },
   "source": [
    "# Generate all training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ruxs_XBEJ2YX"
   },
   "outputs": [],
   "source": [
    "train_lines = []\n",
    "train_target = []\n",
    "\n",
    "def generatedata():\n",
    "  for cate in all_categories:\n",
    "    for line in category_lines[cate]:\n",
    "      train_lines.append(lineToTensor(line.lower()).sum(0))\n",
    "      train_target.append(all_categories.index(cate))\n",
    "\n",
    "generatedata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RBGvJ1MhJ7Kl"
   },
   "outputs": [],
   "source": [
    "train_lines = np.array(train_lines)\n",
    "train_target = np.array(train_target)\n",
    "train_lines = train_lines.squeeze(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2n0qdRrLJBM"
   },
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "c8yfnMbKLNcB"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_lines, train_target, test_size=0.20, random_state=42,stratify = train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDP75YTpsDbE"
   },
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xJw4-1X-qQmA"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.eager.monitoring import Metric\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "#,kernel_regularizer=tf.keras.regularizers.l2(0.001)\n",
    "def build_model(X):\n",
    "  inp = tf.keras.Input((X.shape[1],))\n",
    "  x = tf.keras.layers.Dense(1024, input_dim = X.shape[1] , activation = 'relu')(inp)\n",
    "  x = tf.keras.layers.Dense(512,activation = 'swish')(x) \n",
    "  #x = tf.keras.layers.Dense(256,activation = 'swish')(x)\n",
    "  #x = tf.keras.layers.Dense(128,activation = 'swish')(x)\n",
    "  x = tf.keras.layers.Dense(18,activation = 'softmax')(x) \n",
    "  model = tf.keras.models.Model(inputs=inp, outputs=x)\n",
    "  #lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-3,decay_steps=10000,decay_rate=0.9)\n",
    "  opt = tf.keras.optimizers.Adam(learning_rate=1e-03)\n",
    "  model.compile(loss = 'sparse_categorical_crossentropy' , optimizer = opt, metrics = ['sparse_categorical_accuracy']) \n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LhVHt5i8qzUa"
   },
   "outputs": [],
   "source": [
    "model = build_model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9nmF1oVXqzJQ",
    "outputId": "4cf307d4-32ec-4c57-b44b-b9e920dc9161"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 58)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              60416     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 18)                9234      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 594,450\n",
      "Trainable params: 594,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZet4RWjPrC9",
    "outputId": "519d5956-cb4e-4f3c-e080-6286c1bcbdd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "502/502 [==============================] - 6s 10ms/step - loss: 1.1581 - sparse_categorical_accuracy: 0.6542 - val_loss: 0.9903 - val_sparse_categorical_accuracy: 0.7024 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.8980 - sparse_categorical_accuracy: 0.7235 - val_loss: 0.9074 - val_sparse_categorical_accuracy: 0.7126 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.8085 - sparse_categorical_accuracy: 0.7453 - val_loss: 0.8409 - val_sparse_categorical_accuracy: 0.7385 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.7514 - sparse_categorical_accuracy: 0.7571 - val_loss: 0.8684 - val_sparse_categorical_accuracy: 0.7310 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.7107 - sparse_categorical_accuracy: 0.7680 - val_loss: 0.8599 - val_sparse_categorical_accuracy: 0.7270 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.6682 - sparse_categorical_accuracy: 0.7764 - val_loss: 0.8255 - val_sparse_categorical_accuracy: 0.7412 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.6322 - sparse_categorical_accuracy: 0.7890 - val_loss: 0.8399 - val_sparse_categorical_accuracy: 0.7402 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "502/502 [==============================] - 6s 12ms/step - loss: 0.6072 - sparse_categorical_accuracy: 0.7943 - val_loss: 0.8535 - val_sparse_categorical_accuracy: 0.7445 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "502/502 [==============================] - 5s 11ms/step - loss: 0.5676 - sparse_categorical_accuracy: 0.8103 - val_loss: 0.8476 - val_sparse_categorical_accuracy: 0.7440 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.5337 - sparse_categorical_accuracy: 0.8164 - val_loss: 0.8833 - val_sparse_categorical_accuracy: 0.7390 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "502/502 [==============================] - 6s 11ms/step - loss: 0.5039 - sparse_categorical_accuracy: 0.8247 - val_loss: 0.8994 - val_sparse_categorical_accuracy: 0.7390 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "502/502 [==============================] - 5s 11ms/step - loss: 0.3903 - sparse_categorical_accuracy: 0.8654 - val_loss: 0.8553 - val_sparse_categorical_accuracy: 0.7529 - lr: 1.0000e-04\n",
      "Epoch 13/30\n",
      "502/502 [==============================] - 6s 11ms/step - loss: 0.3622 - sparse_categorical_accuracy: 0.8761 - val_loss: 0.8732 - val_sparse_categorical_accuracy: 0.7524 - lr: 1.0000e-04\n",
      "Epoch 14/30\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.3486 - sparse_categorical_accuracy: 0.8799 - val_loss: 0.8865 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-04\n",
      "Epoch 15/30\n",
      "502/502 [==============================] - 5s 11ms/step - loss: 0.3377 - sparse_categorical_accuracy: 0.8831 - val_loss: 0.8992 - val_sparse_categorical_accuracy: 0.7479 - lr: 1.0000e-04\n",
      "Epoch 16/30\n",
      "502/502 [==============================] - 5s 11ms/step - loss: 0.3186 - sparse_categorical_accuracy: 0.8925 - val_loss: 0.8997 - val_sparse_categorical_accuracy: 0.7494 - lr: 1.0000e-05\n",
      "Epoch 17/30\n",
      "502/502 [==============================] - 5s 11ms/step - loss: 0.3168 - sparse_categorical_accuracy: 0.8920 - val_loss: 0.9011 - val_sparse_categorical_accuracy: 0.7487 - lr: 1.0000e-05\n",
      "Epoch 18/30\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.3154 - sparse_categorical_accuracy: 0.8928 - val_loss: 0.9031 - val_sparse_categorical_accuracy: 0.7487 - lr: 1.0000e-05\n",
      "Epoch 19/30\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.3130 - sparse_categorical_accuracy: 0.8937 - val_loss: 0.9033 - val_sparse_categorical_accuracy: 0.7487 - lr: 1.0000e-06\n",
      "Epoch 20/30\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.3129 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.9034 - val_sparse_categorical_accuracy: 0.7487 - lr: 1.0000e-06\n",
      "Epoch 21/30\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.3128 - sparse_categorical_accuracy: 0.8938 - val_loss: 0.9036 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-06\n",
      "Epoch 22/30\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.3125 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.9036 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-07\n",
      "Epoch 23/30\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.3125 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.9037 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-07\n",
      "Epoch 24/30\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.3125 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.9037 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-07\n",
      "Epoch 25/30\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.3125 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.9037 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-08\n",
      "Epoch 26/30\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.3125 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.9037 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-08\n",
      "Epoch 27/30\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.3125 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.9037 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-08\n",
      "Epoch 28/30\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.3125 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.9037 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-09\n",
      "Epoch 29/30\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.3125 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.9037 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-09\n",
      "Epoch 30/30\n",
      "502/502 [==============================] - 5s 10ms/step - loss: 0.3125 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.9037 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-09\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='tutorial.h5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_sparse_categorical_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_sparse_categorical_accuracy',factor=0.1,patience=3)\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30,batch_size = 32, validation_data=(X_test, y_test),callbacks=[model_checkpoint_callback,lr_schedule] ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfAGXDMgMcxW"
   },
   "source": [
    "# Loading the Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "L2IvQzvJPq_d"
   },
   "outputs": [],
   "source": [
    "model = build_model(X_train)\n",
    "model.load_weights('/content/tutorial.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fipg7FNibJ2g",
    "outputId": "25852ea8-5793-4000-f900-660d3b951367"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 58)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1024)              60416     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 18)                9234      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 594,450\n",
      "Trainable params: 594,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jq4DnMTXPq4a"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1zCcQK8zcOYa"
   },
   "outputs": [],
   "source": [
    "y_pred = y_pred.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeoyxlvYe5Jx"
   },
   "source": [
    "# Calculating Overall Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3EbUYPW3e4m5",
    "outputId": "561af67b-7162-4dc8-9134-2d8c429d4dd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Overall accuracy score is 0.7529265255292652\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f'The Overall accuracy score is {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iG9UQxffPnV"
   },
   "source": [
    "# Inference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHOCq3N_lbgT"
   },
   "source": [
    "I am Gonna Test with few samples \n",
    "\n",
    "Sabbagh ---> Arabic\n",
    "\n",
    "Gregory ---> English\n",
    "\n",
    "Bicchieri ---> Italian\n",
    "\n",
    "Theofilopoulos ---> Greek\n",
    "\n",
    "Sokolof ---> Polish\n",
    "\n",
    "Xiong ---> Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNhNMfqmfNeQ",
    "outputId": "695caa5b-3a78-41d5-aa7b-4de5b9b103b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xiong\n",
      "xiong ----> Chinese\n",
      "sokolof\n",
      "sokolof ----> Polish\n",
      "sabbagh\n",
      "sabbagh ----> Arabic\n",
      "gregory\n",
      "gregory ----> English\n",
      "bicchieri\n",
      "bicchieri ----> Italian\n",
      "theofilopoulos\n",
      "theofilopoulos ----> Greek\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for _ in range(6):\n",
    "\n",
    "  surname = str(input())\n",
    "\n",
    "  tensor = lineToTensor(surname.lower()).sum(0)\n",
    "  \n",
    "  pred = model.predict(tensor)\n",
    "  \n",
    "  pred = pred.argmax(axis = 1)\n",
    "  \n",
    "  print(f'{surname} ----> {all_categories[pred[0]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yeRx6lkVLryf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "CS6120 - Tensorflow-tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
