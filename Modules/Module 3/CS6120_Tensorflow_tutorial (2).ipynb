{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS6120 - Tensorflow-tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CS6120 Natural Language Processing by Professor Uzair Ahmad. \n",
        "\n",
        "## Tensorflow Tutorial. \n",
        "\n",
        "## In this tutorial we are gonna learn about building deep neural networks with tensorflow/keras. For this tutorial we are going to build a classifier model to classify the given surname. \n",
        "\n",
        "## This work is inspired from https://github.com/DrUzair/NLP/tree/master/textclassification/surnames/mlp. "
      ],
      "metadata": {
        "id": "kXoi1PrTpeHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "XLVBxSaDCxeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import unicodedata\n",
        "import string\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "AJK_Dzq8q2BU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "yu--Nj7Wq2lq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e9s4lnVFobM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c012fb8d-c554-405a-acad-6fb065bff11f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "category = Vietnamese / line = Phi\n",
            "category = Spanish / line = Reyes\n",
            "category = Arabic / line = Zogby\n",
            "category = Dutch / line = Vliert\n",
            "category = Greek / line = Dasios\n",
            "category = German / line = Breisacher\n",
            "category = Chinese / line = Rao\n",
            "category = Italian / line = Piovene\n",
            "category = French / line = Langlois\n",
            "category = Greek / line = Kouropoulos\n"
          ]
        }
      ],
      "source": [
        "all_letters = string.ascii_letters + \" .,;'-\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "def findFiles(path): return glob.glob(path)\n",
        "\n",
        "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_letters\n",
        "    )\n",
        "\n",
        "# Read a file and split into lines\n",
        "def readLines(filename):\n",
        "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "    return [unicodeToAscii(line) for line in lines]\n",
        "\n",
        "# Find letter index from all_letters, e.g. \"a\" = 0\n",
        "def letterToIndex(letter):\n",
        "    return all_letters.find(letter)\n",
        "\n",
        "# Turn a line into a <line_length x 1 x n_letters>,\n",
        "# or an array of one-hot letter vectors\n",
        "def lineToTensor(line):\n",
        "    tensor = np.zeros((len(line), 1, n_letters))\n",
        "    for li, letter in enumerate(line):\n",
        "        tensor[li][0][letterToIndex(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "# Build the category_lines dictionary, a list of lines per category\n",
        "category_lines = {}\n",
        "all_categories = []\n",
        "for filename in findFiles('/content/drive/MyDrive/names_data/names/*.txt'):\n",
        "    category = filename.split(\"/\")[-1].split('.')[0].replace('names\\\\','')\n",
        "    all_categories.append(category)\n",
        "    lines = readLines(filename)\n",
        "    category_lines[category] = lines\n",
        "\n",
        "n_categories = len(all_categories)\n",
        "\n",
        "import random\n",
        "\n",
        "def randomChoice(l):\n",
        "    return l[random.randint(0, len(l) - 1)] \n",
        "\n",
        "\n",
        "def randomTrainingExample():\n",
        "    category = randomChoice(all_categories)\n",
        "    line = randomChoice(category_lines[category])\n",
        "    category_tensor = np.array([all_categories.index(category)])\n",
        "    line_tensor = lineToTensor(line.lower())\n",
        "    return category, line, category_tensor, line_tensor\n",
        "\n",
        "def test():\n",
        "    for i in range(10):\n",
        "        category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "        print('category =', category, '/ line =', line)\n",
        "\n",
        "test()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate all training samples"
      ],
      "metadata": {
        "id": "pRHfgxFhLF7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_lines = []\n",
        "train_target = []\n",
        "\n",
        "def generatedata():\n",
        "  for cate in all_categories:\n",
        "    for line in category_lines[cate]:\n",
        "      train_lines.append(lineToTensor(line.lower()).sum(0))\n",
        "      train_target.append(all_categories.index(cate))\n",
        "\n",
        "generatedata()"
      ],
      "metadata": {
        "id": "Ruxs_XBEJ2YX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lines = np.array(train_lines)\n",
        "train_target = np.array(train_target)\n",
        "train_lines = train_lines.squeeze(axis=1)"
      ],
      "metadata": {
        "id": "RBGvJ1MhJ7Kl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Test Split"
      ],
      "metadata": {
        "id": "-2n0qdRrLJBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_lines, train_target, test_size=0.20, random_state=42,stratify = train_target)"
      ],
      "metadata": {
        "id": "c8yfnMbKLNcB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build model"
      ],
      "metadata": {
        "id": "WDP75YTpsDbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.eager.monitoring import Metric\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#,kernel_regularizer=tf.keras.regularizers.l2(0.001)\n",
        "def build_model(X):\n",
        "  inp = tf.keras.Input((X.shape[1],))\n",
        "  x = tf.keras.layers.Dense(1024, input_dim = X.shape[1] , activation = 'relu')(inp)\n",
        "  x = tf.keras.layers.Dense(512,activation = 'swish')(x) \n",
        "  #x = tf.keras.layers.Dense(256,activation = 'swish')(x)\n",
        "  #x = tf.keras.layers.Dense(128,activation = 'swish')(x)\n",
        "  x = tf.keras.layers.Dense(18,activation = 'softmax')(x) \n",
        "  model = tf.keras.models.Model(inputs=inp, outputs=x)\n",
        "  #lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-3,decay_steps=10000,decay_rate=0.9)\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=1e-03)\n",
        "  model.compile(loss = 'sparse_categorical_crossentropy' , optimizer = opt, metrics = ['sparse_categorical_accuracy']) \n",
        "  return model\n"
      ],
      "metadata": {
        "id": "xJw4-1X-qQmA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(X_train)"
      ],
      "metadata": {
        "id": "LhVHt5i8qzUa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "9nmF1oVXqzJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf307d4-32ec-4c57-b44b-b9e920dc9161"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 58)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              60416     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 18)                9234      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 594,450\n",
            "Trainable params: 594,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='tutorial.h5',\n",
        "    save_weights_only=True,\n",
        "    monitor='val_sparse_categorical_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_sparse_categorical_accuracy',factor=0.1,patience=3)\n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=30,batch_size = 32, validation_data=(X_test, y_test),callbacks=[model_checkpoint_callback,lr_schedule] ) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZet4RWjPrC9",
        "outputId": "519d5956-cb4e-4f3c-e080-6286c1bcbdd2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "502/502 [==============================] - 6s 10ms/step - loss: 1.1581 - sparse_categorical_accuracy: 0.6542 - val_loss: 0.9903 - val_sparse_categorical_accuracy: 0.7024 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.8980 - sparse_categorical_accuracy: 0.7235 - val_loss: 0.9074 - val_sparse_categorical_accuracy: 0.7126 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.8085 - sparse_categorical_accuracy: 0.7453 - val_loss: 0.8409 - val_sparse_categorical_accuracy: 0.7385 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.7514 - sparse_categorical_accuracy: 0.7571 - val_loss: 0.8684 - val_sparse_categorical_accuracy: 0.7310 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.7107 - sparse_categorical_accuracy: 0.7680 - val_loss: 0.8599 - val_sparse_categorical_accuracy: 0.7270 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.6682 - sparse_categorical_accuracy: 0.7764 - val_loss: 0.8255 - val_sparse_categorical_accuracy: 0.7412 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.6322 - sparse_categorical_accuracy: 0.7890 - val_loss: 0.8399 - val_sparse_categorical_accuracy: 0.7402 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "502/502 [==============================] - 6s 12ms/step - loss: 0.6072 - sparse_categorical_accuracy: 0.7943 - val_loss: 0.8535 - val_sparse_categorical_accuracy: 0.7445 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "502/502 [==============================] - 5s 11ms/step - loss: 0.5676 - sparse_categorical_accuracy: 0.8103 - val_loss: 0.8476 - val_sparse_categorical_accuracy: 0.7440 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.5337 - sparse_categorical_accuracy: 0.8164 - val_loss: 0.8833 - val_sparse_categorical_accuracy: 0.7390 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "502/502 [==============================] - 6s 11ms/step - loss: 0.5039 - sparse_categorical_accuracy: 0.8247 - val_loss: 0.8994 - val_sparse_categorical_accuracy: 0.7390 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "502/502 [==============================] - 5s 11ms/step - loss: 0.3903 - sparse_categorical_accuracy: 0.8654 - val_loss: 0.8553 - val_sparse_categorical_accuracy: 0.7529 - lr: 1.0000e-04\n",
            "Epoch 13/30\n",
            "502/502 [==============================] - 6s 11ms/step - loss: 0.3622 - sparse_categorical_accuracy: 0.8761 - val_loss: 0.8732 - val_sparse_categorical_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 14/30\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.3486 - sparse_categorical_accuracy: 0.8799 - val_loss: 0.8865 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-04\n",
            "Epoch 15/30\n",
            "502/502 [==============================] - 5s 11ms/step - loss: 0.3377 - sparse_categorical_accuracy: 0.8831 - val_loss: 0.8992 - val_sparse_categorical_accuracy: 0.7479 - lr: 1.0000e-04\n",
            "Epoch 16/30\n",
            "502/502 [==============================] - 5s 11ms/step - loss: 0.3186 - sparse_categorical_accuracy: 0.8925 - val_loss: 0.8997 - val_sparse_categorical_accuracy: 0.7494 - lr: 1.0000e-05\n",
            "Epoch 17/30\n",
            "502/502 [==============================] - 5s 11ms/step - loss: 0.3168 - sparse_categorical_accuracy: 0.8920 - val_loss: 0.9011 - val_sparse_categorical_accuracy: 0.7487 - lr: 1.0000e-05\n",
            "Epoch 18/30\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.3154 - sparse_categorical_accuracy: 0.8928 - val_loss: 0.9031 - val_sparse_categorical_accuracy: 0.7487 - lr: 1.0000e-05\n",
            "Epoch 19/30\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.3130 - sparse_categorical_accuracy: 0.8937 - val_loss: 0.9033 - val_sparse_categorical_accuracy: 0.7487 - lr: 1.0000e-06\n",
            "Epoch 20/30\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.3129 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.9034 - val_sparse_categorical_accuracy: 0.7487 - lr: 1.0000e-06\n",
            "Epoch 21/30\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.3128 - sparse_categorical_accuracy: 0.8938 - val_loss: 0.9036 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-06\n",
            "Epoch 22/30\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.3125 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.9036 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-07\n",
            "Epoch 23/30\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.3125 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.9037 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-07\n",
            "Epoch 24/30\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.3125 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.9037 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-07\n",
            "Epoch 25/30\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.3125 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.9037 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-08\n",
            "Epoch 26/30\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.3125 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.9037 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-08\n",
            "Epoch 27/30\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.3125 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.9037 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-08\n",
            "Epoch 28/30\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.3125 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.9037 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-09\n",
            "Epoch 29/30\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.3125 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.9037 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-09\n",
            "Epoch 30/30\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.3125 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.9037 - val_sparse_categorical_accuracy: 0.7484 - lr: 1.0000e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Best model"
      ],
      "metadata": {
        "id": "KfAGXDMgMcxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(X_train)\n",
        "model.load_weights('/content/tutorial.h5')"
      ],
      "metadata": {
        "id": "L2IvQzvJPq_d"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fipg7FNibJ2g",
        "outputId": "25852ea8-5793-4000-f900-660d3b951367"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 58)]              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1024)              60416     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 18)                9234      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 594,450\n",
            "Trainable params: 594,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "jq4DnMTXPq4a"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_pred.argmax(axis = 1)"
      ],
      "metadata": {
        "id": "1zCcQK8zcOYa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating Overall Accuracy"
      ],
      "metadata": {
        "id": "AeoyxlvYe5Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(f'The Overall accuracy score is {accuracy_score(y_test, y_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EbUYPW3e4m5",
        "outputId": "561af67b-7162-4dc8-9134-2d8c429d4dd3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Overall accuracy score is 0.7529265255292652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference "
      ],
      "metadata": {
        "id": "4iG9UQxffPnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am Gonna Test with few samples \n",
        "\n",
        "Sabbagh ---> Arabic\n",
        "\n",
        "Gregory ---> English\n",
        "\n",
        "Bicchieri ---> Italian\n",
        "\n",
        "Theofilopoulos ---> Greek\n",
        "\n",
        "Sokolof ---> Polish\n",
        "\n",
        "Xiong ---> Chinese"
      ],
      "metadata": {
        "id": "WHOCq3N_lbgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for _ in range(6):\n",
        "\n",
        "  surname = str(input())\n",
        "\n",
        "  tensor = lineToTensor(surname.lower()).sum(0)\n",
        "  \n",
        "  pred = model.predict(tensor)\n",
        "  \n",
        "  pred = pred.argmax(axis = 1)\n",
        "  \n",
        "  print(f'{surname} ----> {all_categories[pred[0]]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNhNMfqmfNeQ",
        "outputId": "695caa5b-3a78-41d5-aa7b-4de5b9b103b4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xiong\n",
            "xiong ----> Chinese\n",
            "sokolof\n",
            "sokolof ----> Polish\n",
            "sabbagh\n",
            "sabbagh ----> Arabic\n",
            "gregory\n",
            "gregory ----> English\n",
            "bicchieri\n",
            "bicchieri ----> Italian\n",
            "theofilopoulos\n",
            "theofilopoulos ----> Greek\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yeRx6lkVLryf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}